{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset for the 2024 mexican election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this file is to translate the raw data, as included in the New_DB file, into a goup of datasets that resemble the sample photo included in the project. This sample is originated by the collection of the number of posts, and reactions to each one as for different social media profiles for each candidate, Xóchitl Gálvez, Claudia Sheinbaum, and Álvarez Mainez in this upcoming 2024 election.\n",
    "\n",
    "The New_DB file is updated on a daily basis to collect the presence of the candidates in different social media platforms, and the reponse from their audience to it. Update dates are intended to be part as the commit message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will treat Claudia as candidate 1, Galvez as 2, and Mainez as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The days prior to a date for which we´ll sum the number of reactions\n",
    "days = [1,2,3,4,5,6,7,14,21,28]\n",
    "\n",
    "# Dates of published polls to read (as reported by Oraculus.mx)\n",
    "date_strings = [\n",
    "    \"2023-09-15\", \"2023-09-15\", \"2023-10-15\", \"2023-10-15\", \"2023-10-15\", \"2023-10-15\", \"2023-10-15\", \"2023-10-15\", \"2023-10-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-11-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2023-12-15\", \"2024-01-15\", \"2024-01-15\", \"2024-01-15\", \"2024-01-15\", \"2024-01-15\", \"2024-01-15\", \"2024-01-15\"\n",
    "]\n",
    "\n",
    "# Target variables for each polling release (reported share of preference)\n",
    "targets_claudia = [49, 53, 59, 46, 50, 55, 48, 60, 57, 48, 57, 66, 50, 49, 54, 50, 52, 46, 51, 55, 65, 52, 52, 54, 50, 53, 57, 46, 54, 66, 48, 55, 61, 51, 63]\n",
    "\n",
    "targets_galvez = [26, 34, 21, 28, 27, 24, 27, 17, 22, 24, 22, 14, 31, 23, 24, 27, 25, 25, 27, 22, 13, 30, 30, 23, 25, 26, 23, 24, 27, 14, 32, 27, 24, 27, 22]\n",
    "\n",
    "targets_maynez = [18, 7, 5, 8, 15, 9, 10, 9, 7, 8, 7, 6, 7, 17, 8, 10, 10, 14, 3, 5, 6, 7, 10, 9, 6, 5, 9, 11, 3, 2, 10, 2, 5, 5, 4]\n",
    "\n",
    "# Polls correspoding to a date\n",
    "polls = [\"Enkoll\", \"GEA-ISA\", \"Covarrubias\", \"El FInanciero\", \"Enkoll\", \"Mendoza Blanco\", \"Mitofsky\", \"Parametría\", \"Simo\", \"Buendía y Márquez\", \"Covarrubias\", \"Demotecnia\", \"El Financiero\", \"Enkoll\", \"Mendoza Blanco\", \"Mitofsky\", \"Parametría\", \"Reforma\", \"Berumen\", \"Covarrubias\", \"Demotecnia\", \"El Financiero\", \"GEA-ISA\", \"Mendoza Blanco\", \"Mitofsky\", \"Parametría\", \"Simo\", \"Citibanamex\", \"Berumen\", \"Demotecnia\", \"El Financiero\", \"Enkoll\", \"Mendoza Blanco\", \"Mitofsky\", \"Simo\"]\n",
    "\n",
    "#Setting columns to use (see New_DB)\n",
    "columns = ['XPosts', 'Xcomments', 'XRts', 'Xlikes', 'XCommsPPost', 'XRTsPPost', 'XlikesPPost', 'FBPosts', 'FBReactions', 'FBComments', 'FBShares', 'FBReactsPPost', 'FBCommsPPost', 'FBSharesPPost', 'IGPosts', 'IGLikes', 'IGLikesPPost', 'YTPosts', 'YTViews', 'YTViewsPPost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 35, 35, 35, 35)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does every day have a poll? Does every poll have a percentage?\n",
    "len(date_strings), len(targets_claudia), len(targets_galvez), len(polls), len(targets_maynez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-12-15, Poll: Mendoza Blanco, Result: 54\n",
      "Date: 2023-10-15, Poll: Covarrubias, Result: 59\n",
      "Date: 2024-01-15, Poll: El Financiero, Result: 48\n",
      "Date: 2023-11-15, Poll: Covarrubias, Result: 57\n",
      "Date: 2024-01-15, Poll: Berumen, Result: 54\n",
      "Date: 2023-10-15, Poll: Mitofsky, Result: 48\n",
      "Date: 2023-12-15, Poll: El Financiero, Result: 52\n",
      "Date: 2023-11-15, Poll: Parametría, Result: 52\n",
      "Date: 2024-01-15, Poll: Mendoza Blanco, Result: 61\n",
      "Date: 2023-11-15, Poll: Reforma, Result: 46\n",
      "Date: 2023-11-15, Poll: El Financiero, Result: 50\n",
      "Date: 2023-11-15, Poll: Demotecnia, Result: 66\n",
      "Date: 2023-10-15, Poll: Parametría, Result: 60\n",
      "Date: 2023-11-15, Poll: Mendoza Blanco, Result: 54\n",
      "Date: 2023-09-15, Poll: Enkoll, Result: 49\n",
      "Date: 2023-12-15, Poll: Demotecnia, Result: 65\n",
      "Date: 2023-12-15, Poll: Simo, Result: 57\n",
      "Date: 2023-11-15, Poll: Enkoll, Result: 49\n",
      "Date: 2023-12-15, Poll: Mitofsky, Result: 50\n",
      "Date: 2024-01-15, Poll: Simo, Result: 63\n",
      "Date: 2023-10-15, Poll: Simo, Result: 57\n",
      "Date: 2023-11-15, Poll: Buendía y Márquez, Result: 48\n",
      "Date: 2024-01-15, Poll: Demotecnia, Result: 66\n",
      "Date: 2023-10-15, Poll: El FInanciero, Result: 46\n",
      "Date: 2023-12-15, Poll: Berumen, Result: 51\n",
      "Date: 2023-09-15, Poll: GEA-ISA, Result: 53\n",
      "Date: 2023-12-15, Poll: Covarrubias, Result: 55\n",
      "Date: 2024-01-15, Poll: Mitofsky, Result: 51\n",
      "Date: 2024-01-15, Poll: Enkoll, Result: 55\n",
      "Date: 2023-12-15, Poll: GEA-ISA, Result: 52\n",
      "Date: 2023-11-15, Poll: Mitofsky, Result: 50\n",
      "Date: 2023-12-15, Poll: Parametría, Result: 53\n",
      "Date: 2023-10-15, Poll: Enkoll, Result: 50\n",
      "Date: 2023-10-15, Poll: Mendoza Blanco, Result: 55\n",
      "Date: 2023-12-15, Poll: Citibanamex, Result: 46\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Create a set of tuples associating dates with corresponding polls\n",
    "date_poll_set_claudia = set(zip(date_strings, polls, targets_claudia))\n",
    "for i, n, j in date_poll_set_claudia:\n",
    "  print(f\"Date: {i}, Poll: {n}, Result: {j}\")\n",
    "\n",
    "print(len(date_poll_set_claudia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-11-15, Poll: Parametría, Result: 25\n",
      "Date: 2023-11-15, Poll: Mendoza Blanco, Result: 24\n",
      "Date: 2023-11-15, Poll: Reforma, Result: 25\n",
      "Date: 2023-12-15, Poll: Mendoza Blanco, Result: 23\n",
      "Date: 2023-12-15, Poll: Citibanamex, Result: 24\n",
      "Date: 2023-11-15, Poll: Mitofsky, Result: 27\n",
      "Date: 2023-11-15, Poll: Buendía y Márquez, Result: 24\n",
      "Date: 2023-11-15, Poll: Demotecnia, Result: 14\n",
      "Date: 2024-01-15, Poll: El Financiero, Result: 32\n",
      "Date: 2023-10-15, Poll: Enkoll, Result: 27\n",
      "Date: 2024-01-15, Poll: Mendoza Blanco, Result: 24\n",
      "Date: 2023-10-15, Poll: El FInanciero, Result: 28\n",
      "Date: 2024-01-15, Poll: Simo, Result: 22\n",
      "Date: 2023-12-15, Poll: Demotecnia, Result: 13\n",
      "Date: 2023-12-15, Poll: Covarrubias, Result: 22\n",
      "Date: 2023-12-15, Poll: Berumen, Result: 27\n",
      "Date: 2023-12-15, Poll: El Financiero, Result: 30\n",
      "Date: 2023-10-15, Poll: Parametría, Result: 17\n",
      "Date: 2024-01-15, Poll: Mitofsky, Result: 27\n",
      "Date: 2023-11-15, Poll: El Financiero, Result: 31\n",
      "Date: 2023-12-15, Poll: Simo, Result: 23\n",
      "Date: 2024-01-15, Poll: Demotecnia, Result: 14\n",
      "Date: 2023-10-15, Poll: Covarrubias, Result: 21\n",
      "Date: 2023-12-15, Poll: Mitofsky, Result: 25\n",
      "Date: 2023-12-15, Poll: Parametría, Result: 26\n",
      "Date: 2023-11-15, Poll: Covarrubias, Result: 22\n",
      "Date: 2023-09-15, Poll: GEA-ISA, Result: 34\n",
      "Date: 2024-01-15, Poll: Enkoll, Result: 27\n",
      "Date: 2023-09-15, Poll: Enkoll, Result: 26\n",
      "Date: 2023-10-15, Poll: Simo, Result: 22\n",
      "Date: 2023-11-15, Poll: Enkoll, Result: 23\n",
      "Date: 2023-12-15, Poll: GEA-ISA, Result: 30\n",
      "Date: 2024-01-15, Poll: Berumen, Result: 27\n",
      "Date: 2023-10-15, Poll: Mendoza Blanco, Result: 24\n",
      "Date: 2023-10-15, Poll: Mitofsky, Result: 27\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Create a set of tuples associating dates with corresponding polls\n",
    "date_poll_set_galvez = set(zip(date_strings, polls, targets_galvez))\n",
    "for i, n, j in date_poll_set_galvez:\n",
    "  print(f\"Date: {i}, Poll: {n}, Result: {j}\")\n",
    "print(len(date_poll_set_galvez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-10-15, Poll: Parametría, Result: 9\n",
      "Date: 2023-12-15, Poll: Simo, Result: 9\n",
      "Date: 2023-10-15, Poll: Enkoll, Result: 15\n",
      "Date: 2024-01-15, Poll: Simo, Result: 4\n",
      "Date: 2023-12-15, Poll: Berumen, Result: 3\n",
      "Date: 2023-11-15, Poll: El Financiero, Result: 7\n",
      "Date: 2023-11-15, Poll: Mendoza Blanco, Result: 8\n",
      "Date: 2023-12-15, Poll: Parametría, Result: 5\n",
      "Date: 2024-01-15, Poll: Demotecnia, Result: 2\n",
      "Date: 2023-12-15, Poll: Citibanamex, Result: 11\n",
      "Date: 2023-12-15, Poll: GEA-ISA, Result: 10\n",
      "Date: 2023-11-15, Poll: Buendía y Márquez, Result: 8\n",
      "Date: 2023-09-15, Poll: Enkoll, Result: 18\n",
      "Date: 2024-01-15, Poll: Mendoza Blanco, Result: 5\n",
      "Date: 2023-11-15, Poll: Covarrubias, Result: 7\n",
      "Date: 2024-01-15, Poll: El Financiero, Result: 10\n",
      "Date: 2023-10-15, Poll: Mitofsky, Result: 10\n",
      "Date: 2023-09-15, Poll: GEA-ISA, Result: 7\n",
      "Date: 2024-01-15, Poll: Mitofsky, Result: 5\n",
      "Date: 2023-12-15, Poll: Demotecnia, Result: 6\n",
      "Date: 2023-11-15, Poll: Reforma, Result: 14\n",
      "Date: 2023-12-15, Poll: Mitofsky, Result: 6\n",
      "Date: 2023-10-15, Poll: Covarrubias, Result: 5\n",
      "Date: 2023-12-15, Poll: Mendoza Blanco, Result: 9\n",
      "Date: 2023-11-15, Poll: Mitofsky, Result: 10\n",
      "Date: 2023-10-15, Poll: Simo, Result: 7\n",
      "Date: 2024-01-15, Poll: Berumen, Result: 3\n",
      "Date: 2023-11-15, Poll: Enkoll, Result: 17\n",
      "Date: 2023-11-15, Poll: Demotecnia, Result: 6\n",
      "Date: 2023-10-15, Poll: Mendoza Blanco, Result: 9\n",
      "Date: 2023-12-15, Poll: El Financiero, Result: 7\n",
      "Date: 2023-10-15, Poll: El FInanciero, Result: 8\n",
      "Date: 2023-12-15, Poll: Covarrubias, Result: 5\n",
      "Date: 2024-01-15, Poll: Enkoll, Result: 2\n",
      "Date: 2023-11-15, Poll: Parametría, Result: 10\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "# Create a set of tuples associating dates with corresponding polls\n",
    "date_poll_set_maynez = set(zip(date_strings, polls, targets_maynez))\n",
    "for i, n, j in date_poll_set_maynez:\n",
    "  print(f\"Date: {i}, Poll: {n}, Result: {j}\")\n",
    "print(len(date_poll_set_maynez))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "file_path = \"../New_DB.xlsx\"\n",
    "# Read all sheets into a dictionary of DataFrames\n",
    "all_sheets = pd.read_excel(file_path, skiprows=1, sheet_name=None)\n",
    "\n",
    "# Access each DataFrame by sheet name\n",
    "galvez_df = all_sheets[\"Galvez\"]\n",
    "claudia_df = all_sheets[\"Claudia\"]\n",
    "maynez_df = all_sheets[\"Maynez\"]\n",
    "\n",
    "# Convert 'Date' column to datetime if it's not already\n",
    "galvez_df['Date'] = pd.to_datetime(galvez_df['Date'])\n",
    "claudia_df['Date'] = pd.to_datetime(claudia_df['Date'])\n",
    "maynez_df['Date'] = pd.to_datetime(maynez_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We should have 350 'records' And we have 350\n"
     ]
    }
   ],
   "source": [
    "# How mauch data should we have?\n",
    "data = len(days) * len(polls)\n",
    "count = 0\n",
    "for i in days:\n",
    "  for x, y, z in date_poll_set_claudia:\n",
    "    count += 1\n",
    "\n",
    "print(f\"We should have {data} 'records' And we have {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDIA\n",
    "\n",
    "# Specify the directory where you want to save the CSV files\n",
    "output_directory = \"../claudia\"\n",
    "result_dataframes = {}\n",
    "for i in days:\n",
    "  for x, y, z in date_poll_set_claudia:\n",
    "    # Filter rows based on the established date and count the specified number of rows before that\n",
    "    filtered_df = claudia_df.loc[claudia_df['Date'] < x].iloc[-i:]\n",
    "    # Sum the data in the selected rows\n",
    "    sum_result = filtered_df[columns].sum()\n",
    "    # Turn result into a DF and Transpose\n",
    "    pd_result = sum_result.to_frame().T\n",
    "    #Adding metadata columns to the new sum dataframe\n",
    "    pd_result['Candidate'] = 'Claudia'\n",
    "    pd_result['Window'] = i\n",
    "    pd_result['Ref. Date'] = x\n",
    "    pd_result['Institute'] = y\n",
    "    pd_result['Target'] = z\n",
    "    # round the result and output\n",
    "    pd_result = pd_result.round()\n",
    "\n",
    "    # Store the dataframe in the dictionary with a meaningful key\n",
    "    key = f\"1_{i}_{x}_{y}\"\n",
    "    result_dataframes[key] = pd_result\n",
    "\n",
    "    # Save the dataframe to a CSV file in the specified directory\n",
    "    csv_filepath = os.path.join(output_directory, f\"{key}.csv\")\n",
    "    pd_result.to_csv(csv_filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory where you want to save the CSV files\n",
    "output_directory = \"../galvez\"\n",
    "result_dataframes = {}\n",
    "for i in days:\n",
    "  for x, y, z in date_poll_set_galvez:\n",
    "    # Filter rows based on the established date and count the specified number of rows before that\n",
    "    filtered_df = galvez_df.loc[galvez_df['Date'] < x].iloc[-i:]\n",
    "    # Sum the data in the selected rows\n",
    "    sum_result = filtered_df[columns].sum()\n",
    "    # Turn result into a DF and Transpose\n",
    "    pd_result = sum_result.to_frame().T\n",
    "    #Adding metadata columns to the new sum dataframe\n",
    "    pd_result['Candidate'] = 'Galvez'\n",
    "    pd_result['Window'] = i\n",
    "    pd_result['Ref. Date'] = x\n",
    "    pd_result['Institute'] = y\n",
    "    pd_result['Target'] = z\n",
    "    # round the result and output\n",
    "    pd_result = pd_result.round()\n",
    "\n",
    "    # Store the dataframe in the dictionary with a meaningful key\n",
    "    key = f\"2_{i}_{x}_{y}\"\n",
    "    result_dataframes[key] = pd_result\n",
    "\n",
    "    # Save the dataframe to a CSV file in the specified directory\n",
    "    csv_filepath = os.path.join(output_directory, f\"{key}.csv\")\n",
    "    pd_result.to_csv(csv_filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created single column files that correspond to each poll by a date, by candidate. We now need to join corresponding poll results categorized by window time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files matching the pattern 1_1_ successfully combined. Output saved to: ../claudia/1_1.csv\n",
      "CSV files matching the pattern 1_2_ successfully combined. Output saved to: ../claudia/1_2.csv\n",
      "CSV files matching the pattern 1_3_ successfully combined. Output saved to: ../claudia/1_3.csv\n",
      "CSV files matching the pattern 1_4_ successfully combined. Output saved to: ../claudia/1_4.csv\n",
      "CSV files matching the pattern 1_5_ successfully combined. Output saved to: ../claudia/1_5.csv\n",
      "CSV files matching the pattern 1_6_ successfully combined. Output saved to: ../claudia/1_6.csv\n",
      "CSV files matching the pattern 1_7_ successfully combined. Output saved to: ../claudia/1_7.csv\n",
      "CSV files matching the pattern 1_14_ successfully combined. Output saved to: ../claudia/1_14.csv\n",
      "CSV files matching the pattern 1_21_ successfully combined. Output saved to: ../claudia/1_21.csv\n",
      "CSV files matching the pattern 1_28_ successfully combined. Output saved to: ../claudia/1_28.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the directory where your CSV files are located\n",
    "directory = '../claudia'\n",
    "for i in days:\n",
    "\n",
    "    # Specify the pattern for file names to include\n",
    "    file_name_pattern = f'1_{i}_'\n",
    "\n",
    "    # Get a list of CSV files in the directory that match the pattern\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and file.startswith(file_name_pattern)]\n",
    "\n",
    "    # Ensure there are matching CSV files in the directory\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files matching the pattern {file_name_pattern} found in the specified directory.\")\n",
    "    else:\n",
    "        # Read the first CSV file to get the header\n",
    "        first_file_path = os.path.join(directory, csv_files[0])\n",
    "        df_combined = pd.read_csv(first_file_path)\n",
    "\n",
    "        # Loop through the remaining CSV files and concatenate them\n",
    "        for csv_file in csv_files[1:]:\n",
    "            file_path = os.path.join(directory, csv_file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_combined = pd.concat([df_combined, df], ignore_index=True)\n",
    "\n",
    "        # Write the combined DataFrame to a new CSV file\n",
    "        combined_output_path = f'../claudia/1_{i}.csv'\n",
    "        df_combined.to_csv(combined_output_path, index=False)\n",
    "\n",
    "        print(f\"CSV files matching the pattern {file_name_pattern} successfully combined. Output saved to: {combined_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files matching the pattern 2_1_ successfully combined. Output saved to: ../galvez/2_1.csv\n",
      "CSV files matching the pattern 2_2_ successfully combined. Output saved to: ../galvez/2_2.csv\n",
      "CSV files matching the pattern 2_3_ successfully combined. Output saved to: ../galvez/2_3.csv\n",
      "CSV files matching the pattern 2_4_ successfully combined. Output saved to: ../galvez/2_4.csv\n",
      "CSV files matching the pattern 2_5_ successfully combined. Output saved to: ../galvez/2_5.csv\n",
      "CSV files matching the pattern 2_6_ successfully combined. Output saved to: ../galvez/2_6.csv\n",
      "CSV files matching the pattern 2_7_ successfully combined. Output saved to: ../galvez/2_7.csv\n",
      "CSV files matching the pattern 2_14_ successfully combined. Output saved to: ../galvez/2_14.csv\n",
      "CSV files matching the pattern 2_21_ successfully combined. Output saved to: ../galvez/2_21.csv\n",
      "CSV files matching the pattern 2_28_ successfully combined. Output saved to: ../galvez/2_28.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the directory where your CSV files are located\n",
    "directory = '../galvez/'\n",
    "for i in days:\n",
    "\n",
    "    # Specify the pattern for file names to include\n",
    "    file_name_pattern = f'2_{i}_'\n",
    "\n",
    "    # Get a list of CSV files in the directory that match the pattern\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv') and file.startswith(file_name_pattern)]\n",
    "\n",
    "    # Ensure there are matching CSV files in the directory\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files matching the pattern {file_name_pattern} found in the specified directory.\")\n",
    "    else:\n",
    "        # Read the first CSV file to get the header\n",
    "        first_file_path = os.path.join(directory, csv_files[0])\n",
    "        df_combined = pd.read_csv(first_file_path)\n",
    "\n",
    "        # Loop through the remaining CSV files and concatenate them\n",
    "        for csv_file in csv_files[1:]:\n",
    "            file_path = os.path.join(directory, csv_file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_combined = pd.concat([df_combined, df], ignore_index=True)\n",
    "\n",
    "        # Write the combined DataFrame to a new CSV file\n",
    "        combined_output_path = f'../galvez/2_{i}.csv'\n",
    "        df_combined.to_csv(combined_output_path, index=False)\n",
    "\n",
    "        print(f\"CSV files matching the pattern {file_name_pattern} successfully combined. Output saved to: {combined_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process will be repeated to feed the regression models on multiple occasions (as new polls get released and as new posts get interactions on a daily basis). \n",
    "\n",
    "The release of this dataset belongs to the research effort performed by the author of this repository, which hopes to upbring new research based on it since similar databases have not been found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
